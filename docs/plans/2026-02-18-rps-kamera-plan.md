# RPS Realtidskamera ‚Äî Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Skapa `07_rps_kamera.ipynb` ‚Äî en frist√•ende Colab-notebook d√§r elever tr√§nar ett CNN p√• egna bilder och klassificerar sten-sax-p√•se i realtid via webcam.

**Architecture:** Sju notebook-sektioner. Tr√§ningsdata h√§mtas fr√•n Google Drive (f√∂rifyllda exempelmappar fr√•n TF-dataset, eller elevernas egna bilder). Preprocessing sker i en delad funktion som anv√§nds vid b√•de tr√§ning och live-inferens. Realtidskameran drivs av JavaScript i Colab output-cellen; JS anropar Python via `google.colab.kernel.invokeFunction`.

**Tech Stack:** TensorFlow/Keras 3, TensorFlow Datasets, PIL, OpenCV (cv2), google.colab.output, IPython.display.HTML

---

### Task 1: Skapa notebook-fil och cell 1 ‚Äî Intro (markdown)

**Files:**
- Create: `07_rps_kamera.ipynb`

**Step 1: Skapa notebook**

Skapa filen `07_rps_kamera.ipynb` med en enda markdown-cell:

```markdown
# Bygg din egen Sten-Sax-P√•se AI ü§ñ‚úä‚úã‚úåÔ∏è

Du har l√§rt dig hur CNN:er fungerar. Nu bygger du ett fr√•n grunden ‚Äî tr√§nat p√• **dina egna bilder**.

## Vad vi g√∂r
1. Koppla Google Drive och h√§mta tr√§ningsdata
2. Tr√§na ett CNN p√• bilder av sten, sax och p√•se
3. Testa modellen live med din webcam

## Vad du beh√∂ver
- Ett Google-konto med Drive
- En kamera (inbyggd eller extern)
- K√∂r allt uppifr√•n och ned, en cell i taget
```

**Step 2: Verifiera**

√ñppna i Colab, kontrollera att markdown-cellen renderas korrekt.

**Step 3: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add rps camera notebook skeleton with intro"
```

---

### Task 2: Cell 2 ‚Äî Imports

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till kod-cell**

```python
import os
import json
import base64
import numpy as np
import cv2
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import tensorflow_datasets as tfds

from IPython.display import display, HTML
from google.colab import output as colab_output

print(f"TensorFlow: {tf.__version__}")
print(f"Keras: {keras.__version__}")
print("Allt importerat! ‚úì")
```

**Step 2: Verifiera**

K√∂r cellen i Colab. F√∂rv√§ntat output:
```
TensorFlow: 2.x.x
Keras: 3.x.x
Allt importerat! ‚úì
```

**Step 3: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add imports cell"
```

---

### Task 3: Cell 3 ‚Äî Preprocessing-funktion (delad)

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 1: F√∂rbered data

Samma f√∂rbehandlingsfunktion anv√§nds f√∂r **tr√§ningsbilder** och **live-kamerabilder** ‚Äî annars tr√§nar vi p√• en typ av data men testar p√• en annan.
```

**Step 2: L√§gg till kod-cell**

```python
IMG_SIZE = 150  # Alla bilder skalas till 150√ó150 pixlar

def forbehandla_bild(img):
    """
    Tar en numpy RGB-array (valfri storlek) och returnerar
    en normaliserad float32-array med formen (150, 150, 3).
    Anv√§nds vid b√•de tr√§ning och live-inferens.
    """
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
    return img.astype('float32') / 255.0

print(f"Bildstorlek: {IMG_SIZE}√ó{IMG_SIZE} pixlar")
```

**Step 3: Verifiera**

```python
# Snabbtest
dummy = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
result = forbehandla_bild(dummy)
assert result.shape == (150, 150, 3), f"Fel shape: {result.shape}"
assert result.max() <= 1.0, "Inte normaliserat till 0-1"
print("forbehandla_bild() fungerar! ‚úì")
```

**Step 4: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add shared preprocessing function"
```

---

### Task 4: Cell 4 ‚Äî Google Drive

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 2: Google Drive

K√∂r cellen nedan. En popup √∂ppnas ‚Äî logga in med ditt Google-konto och ge tillst√•nd.

Dina bilder sparas i Drive s√• att de finns kvar n√§sta g√•ng du √∂ppnar Colab.
```

**Step 2: L√§gg till kod-cell**

```python
from google.colab import drive
drive.mount('/content/drive')

DRIVE_ROOT = '/content/drive/My Drive'
print(f"Drive kopplat! ‚úì")
print(f"Dina filer ligger under: {DRIVE_ROOT}")
```

**Step 3: Verifiera**

K√∂r cellen. F√∂rv√§ntat output efter inloggning:
```
Drive kopplat! ‚úì
Dina filer ligger under: /content/drive/My Drive
```

---

### Task 5: Cell 5 ‚Äî Exempelmappar (fyll fr√•n TF-dataset)

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 3: Exempeldata

K√∂r den h√§r cellen **en g√•ng** f√∂r att fylla dina Drive-mappar med exempelbilder fr√•n ett f√§rdigt dataset.

Mappstrukturen som skapas:
```
My Drive/
  rps_exempel/
    rock/        ‚Üê ~150 bilder
    paper/       ‚Üê ~150 bilder
    scissors/    ‚Üê ~150 bilder
  rps_eget/
    rock/        ‚Üê tom (fyll p√• med dina egna bilder!)
    paper/       ‚Üê tom
    scissors/    ‚Üê tom
```
```

**Step 2: L√§gg till kod-cell**

```python
EXEMPEL_DIR = f'{DRIVE_ROOT}/rps_exempel'
EGET_DIR    = f'{DRIVE_ROOT}/rps_eget'
KLASSER     = ['rock', 'paper', 'scissors']

def skapa_mappar(base_dir):
    for klass in KLASSER:
        os.makedirs(f'{base_dir}/{klass}', exist_ok=True)

skapa_mappar(EXEMPEL_DIR)
skapa_mappar(EGET_DIR)

def spara_exempelbilder(data_dir, bilder_per_klass=150):
    """H√§mtar rock_paper_scissors fr√•n TF Datasets och sparar som JPG till Drive."""
    ds = tfds.load('rock_paper_scissors', split='train', as_supervised=True)

    r√§knare = [0, 0, 0]
    m√•l     = bilder_per_klass

    for img_tensor, label_tensor in ds:
        i = int(label_tensor.numpy())
        if r√§knare[i] >= m√•l:
            continue

        img_np  = img_tensor.numpy().astype(np.uint8)
        img_pil = Image.fromarray(img_np)
        s√∂kv√§g  = f'{data_dir}/{KLASSER[i]}/{r√§knare[i]:04d}.jpg'
        img_pil.save(s√∂kv√§g, quality=90)
        r√§knare[i] += 1

        if all(r >= m√•l for r in r√§knare):
            break

    for i, klass in enumerate(KLASSER):
        print(f"  {klass}: {r√§knare[i]} bilder sparade")

# Guard: hoppa √∂ver om mappen redan √§r ifylld
rock_dir = Path(f'{EXEMPEL_DIR}/rock')
befintliga = len(list(rock_dir.glob('*.jpg')))

if befintliga >= 50:
    print(f"Exempelmappar redan ifyllda ({befintliga} bilder i rock/). Hoppar √∂ver. ‚úì")
else:
    print("Laddar ner exempelbilder fr√•n TF Datasets...")
    print("(Det h√§r tar ~1-2 minuter ‚Äî k√∂rs bara en g√•ng.)\n")
    spara_exempelbilder(EXEMPEL_DIR)
    print(f"\nKlart! Bilderna ligger nu i Drive under rps_exempel/")
```

**Step 3: Verifiera**

K√∂r cellen. F√∂rv√§ntat output:
```
Laddar ner exempelbilder fr√•n TF Datasets...
(Det h√§r tar ~1-2 minuter ‚Äî k√∂rs bara en g√•ng.)

  rock: 150 bilder sparade
  paper: 150 bilder sparade
  scissors: 150 bilder sparade

Klart! Bilderna ligger nu i Drive under rps_exempel/
```

K√∂r om cellen ‚Äî ska visa:
```
Exempelmappar redan ifyllda (150 bilder i rock/). Hoppar √∂ver. ‚úì
```

**Step 4: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add drive folder setup and TF dataset download"
```

---

### Task 6: Cell 6 ‚Äî V√§lj dataset

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 4: V√§lj dataset

√Ñndra `DATASET` nedan f√∂r att v√§lja vilka bilder modellen ska tr√§nas p√•.

| V√§rde | Bilder |
|-------|--------|
| `'exempel'` | De 150 exempelbilder vi just laddade ner |
| `'eget'` | Dina egna bilder i `rps_eget/` |

**Hur l√§gger man till egna bilder?**
1. √ñppna [drive.google.com](https://drive.google.com)
2. Navigera till `rps_eget/rock/` och ladda upp foton av en knytn√§ve
3. G√∂r samma f√∂r `paper/` och `scissors/`
4. Minst 30 bilder per klass rekommenderas, ju fler desto b√§ttre
5. JPG, PNG, WebP ‚Äî alla format fungerar
```

**Step 2: L√§gg till kod-cell**

```python
DATASET = 'exempel'  # √Ñndra till 'eget' n√§r du har egna bilder

if DATASET == 'exempel':
    DATA_DIR = EXEMPEL_DIR
elif DATASET == 'eget':
    DATA_DIR = EGET_DIR
else:
    raise ValueError(f"DATASET m√•ste vara 'exempel' eller 'eget', fick: '{DATASET}'")

print(f"Anv√§nder dataset: '{DATASET}'")
print(f"S√∂kv√§g: {DATA_DIR}")

# R√§kna bilder
for klass in KLASSER:
    klass_path = Path(f'{DATA_DIR}/{klass}')
    filer = list(klass_path.glob('*.jpg')) + list(klass_path.glob('*.jpeg')) + \
            list(klass_path.glob('*.png')) + list(klass_path.glob('*.webp'))
    print(f"  {klass}: {len(filer)} bilder")
```

**Step 3: Verifiera**

Med `DATASET = 'exempel'`:
```
Anv√§nder dataset: 'exempel'
S√∂kv√§g: /content/drive/My Drive/rps_exempel
  rock: 150 bilder
  paper: 150 bilder
  scissors: 150 bilder
```

---

### Task 7: Cell 7 ‚Äî Ladda bilder + visa exempel

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 5: Ladda och tr√§na
```

**Step 2: L√§gg till kod-cell**

```python
def ladda_bilder(data_dir):
    """
    Laddar alla bilder fr√•n data_dir/{rock,paper,scissors}/.
    Returnerar X (numpy-array med bilder) och y (klassetiketter).
    St√∂djer JPG, JPEG, PNG, WebP.
    """
    X, y = [], []
    totalt = 0
    fel    = 0

    for i, klass in enumerate(KLASSER):
        klass_dir = Path(f'{data_dir}/{klass}')
        filer = (list(klass_dir.glob('*.jpg'))  +
                 list(klass_dir.glob('*.jpeg')) +
                 list(klass_dir.glob('*.png'))  +
                 list(klass_dir.glob('*.webp')))

        laddade = 0
        for fil in filer:
            try:
                img = Image.open(fil).convert('RGB')   # hanterar RGBA, gr√•skala etc.
                img = np.array(img)
                img = forbehandla_bild(img)
                X.append(img)
                y.append(i)
                laddade += 1
            except Exception as e:
                print(f"  Varning: kunde inte ladda {fil.name}: {e}")
                fel += 1

        print(f"  {klass}: {laddade} bilder laddade")
        totalt += laddade

    print(f"\nTotalt: {totalt} bilder ({fel} fel)")
    return np.array(X, dtype='float32'), np.array(y, dtype='int32')

print("Laddar bilder fr√•n Drive...")
X, y = ladda_bilder(DATA_DIR)
print(f"X.shape: {X.shape}   y.shape: {y.shape}")
```

**Step 3: L√§gg till kodcell ‚Äî visa bilder**

```python
# Visa 12 slumpm√§ssiga bilder
fig, axes = plt.subplots(2, 6, figsize=(15, 5))
idx = np.random.choice(len(X), 12, replace=False)

for ax, i in zip(axes.flatten(), idx):
    ax.imshow(X[i])
    ax.set_title(KLASSER[y[i]])
    ax.axis('off')

plt.suptitle('Exempelbilder fr√•n dataset', fontsize=14)
plt.tight_layout()
plt.show()
```

**Step 4: Verifiera**

Output ska visa 12 bilder m√§rkta med rock/paper/scissors, inga felmeddelanden.

**Step 5: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add image loading and preview cells"
```

---

### Task 8: Cell 8 ‚Äî Dela upp data + bygg modell + tr√§na

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till kod-cell ‚Äî dela upp**

```python
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Tr√§ning:    {len(X_train)} bilder")
print(f"Validering: {len(X_val)} bilder")
```

**Step 2: L√§gg till kod-cell ‚Äî bygg CNN**

```python
model = keras.Sequential([
    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),

    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(3, activation='softmax')  # rock, paper, scissors
])

model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()
```

**Step 3: L√§gg till kod-cell ‚Äî tr√§na**

```python
print("Tr√§nar modellen...")

history = model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=15,
    batch_size=32,
    verbose=1
)

_, val_acc = model.evaluate(X_val, y_val, verbose=0)
print(f"\nValiderings-accuracy: {val_acc*100:.1f}%")
```

**Step 4: Verifiera**

Modellen ska tr√§na 15 epochs utan fel. F√∂rv√§ntat val_accuracy med exempeldata: >85%.

**Step 5: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add train/val split, CNN architecture, training cells"
```

---

### Task 9: Cell 9 ‚Äî Utv√§rdera (kurvor + confusion matrix)

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 6: Utv√§rdera modellen
```

**Step 2: L√§gg till kod-cell**

```python
fig, axes = plt.subplots(1, 2, figsize=(12, 4))

# Tr√§ningskurvor
axes[0].plot(history.history['loss'],     label='Tr√§ning')
axes[0].plot(history.history['val_loss'], label='Validering')
axes[0].set_title('F√∂rlust (Loss)')
axes[0].set_xlabel('Epoch')
axes[0].legend()

axes[1].plot(history.history['accuracy'],     label='Tr√§ning')
axes[1].plot(history.history['val_accuracy'], label='Validering')
axes[1].set_title('Accuracy')
axes[1].set_xlabel('Epoch')
axes[1].legend()

plt.tight_layout()
plt.show()

# Confusion matrix
y_pred = np.argmax(model.predict(X_val, verbose=0), axis=1)
cm     = confusion_matrix(y_val, y_pred)

plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=KLASSER, yticklabels=KLASSER)
plt.title('Confusion Matrix (validering)')
plt.ylabel('Sant')
plt.xlabel('F√∂rutsagt')
plt.tight_layout()
plt.show()
```

**Step 3: Verifiera**

Tv√• plottar ska renderas: tr√§ningskurvor + confusion matrix utan fel.

**Step 4: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add evaluation plots and confusion matrix"
```

---

### Task 10: Cell 10 ‚Äî Realtidskamera (hj√§lpfunktion)

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till markdown-cell**

```markdown
---
## Del 7: Testa med webcam i realtid! üì∑

K√∂r cellen nedan ‚Äî din kamera startar och modellen gissar vad den ser var 500:e millisekund.

H√•ll upp handen med sten ‚úä, p√•se ‚úã eller sax ‚úåÔ∏è framf√∂r kameran!
```

**Step 2: L√§gg till kod-cell ‚Äî definiera starta_kamera**

```python
def starta_kamera(model, klassnamn=None):
    """
    Startar en live-kamerafeed i Colab och klassificerar varje frame.
    Visar procentuella sannolikheter uppdaterade var 500ms.

    Args:
        model:      tr√§nad Keras-modell med softmax-output
        klassnamn:  lista med klassnamn, t.ex. ['rock', 'paper', 'scissors']
    """
    if klassnamn is None:
        klassnamn = KLASSER

    # --- Python-callback som JS anropar ---
    def klassificera_callback(img_b64):
        binary    = base64.b64decode(img_b64.split(',')[1])
        img_array = np.frombuffer(binary, dtype=np.uint8)
        img_bgr   = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        img_rgb   = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        img_proc  = forbehandla_bild(img_rgb)
        img_input = np.expand_dims(img_proc, axis=0)
        pred      = model.predict(img_input, verbose=0)[0]
        return {k: float(v) for k, v in zip(klassnamn, pred)}

    colab_output.register_callback('klassificera_bild', klassificera_callback)

    # --- HTML + JS ---
    klass_json  = json.dumps(klassnamn)
    emoji_map   = json.dumps({'rock': '‚úä', 'paper': '‚úã', 'scissors': '‚úåÔ∏è'})

    html = f"""
<div id="rps-wrap" style="font-family: 'Courier New', monospace; max-width: 400px;">
  <video id="rps-video" width="320" height="240" autoplay playsinline
         style="border: 2px solid #555; border-radius: 6px; display:block;"></video>
  <div id="rps-pred" style="margin-top:10px; font-size:15px; line-height:2.0;">
    Startar kamera...
  </div>
</div>

<script>
(async () => {{
  const video   = document.getElementById('rps-video');
  const predDiv = document.getElementById('rps-pred');
  const klasser = {klass_json};
  const emojis  = {emoji_map};

  // Starta webcam
  const stream  = await navigator.mediaDevices.getUserMedia({{video: true}});
  video.srcObject = stream;
  await video.play();

  const canvas  = document.createElement('canvas');
  canvas.width  = video.videoWidth  || 320;
  canvas.height = video.videoHeight || 240;

  async function uppdatera() {{
    canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);
    const imgData = canvas.toDataURL('image/jpeg', 0.7);

    let result;
    try {{
      result = await google.colab.kernel.invokeFunction(
        'klassificera_bild', [imgData], {{}}
      );
    }} catch (e) {{
      predDiv.innerHTML = '<span style="color:red;">Fel: ' + e.message + '</span>';
      return;
    }}

    const preds = result.data['application/json'];

    // Hitta b√§sta klass
    let b√§staKlass = klasser[0];
    let b√§staV√§rde = 0;
    for (const k of klasser) {{
      if (preds[k] > b√§staV√§rde) {{ b√§staV√§rde = preds[k]; b√§staKlass = k; }}
    }}

    // Bygg HTML-staplar
    let html = '';
    for (const k of klasser) {{
      const pct    = Math.round(preds[k] * 100);
      const filled = Math.round(preds[k] * 20);
      const bar    = '‚ñà'.repeat(Math.max(0, filled)) +
                     '‚ñë'.repeat(Math.max(0, 20 - filled));
      const isTop  = (k === b√§staKlass);
      const color  = isTop
        ? (pct >= 60 ? '#22c55e' : '#f59e0b')
        : '#9ca3af';
      const weight = isTop ? 'bold' : 'normal';
      const emoji  = emojis[k] || '?';
      html += `<div style="color:${{color}};font-weight:${{weight}};">` +
              `${{emoji}} ${{k.padEnd(9)}} ${{bar}} ${{String(pct).padStart(3)}}%</div>`;
    }}
    predDiv.innerHTML = html;
  }}

  setInterval(uppdatera, 500);
}})();
</script>
"""
    display(HTML(html))
    print("Kameran √§r ig√•ng! H√•ll upp handen framf√∂r kameran. ‚úì")
```

**Step 3: Verifiera**

K√∂r cellen ‚Äî ingen output, bara funktionen definieras.

**Step 4: Commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add real-time camera helper function"
```

---

### Task 11: Cell 11 ‚Äî Starta kameran

**Files:**
- Modify: `07_rps_kamera.ipynb`

**Step 1: L√§gg till kod-cell**

```python
starta_kamera(model)
```

**Step 2: Verifiera**

K√∂r cellen. Webbl√§saren ber om kamera-tillst√•nd. Efter tillst√•nd:
- Live-videofeed visas (320√ó240)
- Under videon: tre rader med ‚úä/‚úã/‚úåÔ∏è, staplar och procentsatser
- Procentsatserna uppdateras var 500ms utan fel i konsolen
- Gr√∂n f√§rg p√• den klass med h√∂gst sannolikhet (>60%)
- Orange f√§rg om modellen √§r os√§ker (b√§sta klassen <60%)

**Step 3: Testa edge cases**
- H√•ll upp sten ‚Üí rock ska dominera
- H√•ll upp p√•se ‚Üí paper ska dominera
- H√•ll upp sax ‚Üí scissors ska dominera
- Tom bakgrund ‚Üí sannolikheter ska f√∂rdelas j√§mnt

**Step 4: Final commit**

```bash
git add 07_rps_kamera.ipynb
git commit -m "feat: add camera trigger cell ‚Äî notebook complete"
```

---

## Verifieringschecklista (hela notebook)

- [ ] Alla celler k√∂rs utan fel fr√•n topp till botten i Colab
- [ ] Guard i cell 5 hoppar korrekt √∂ver nedladdning vid omk√∂rning
- [ ] `DATASET = 'eget'` med tomma mappar ger tydligt felmeddelande (FileNotFoundError eller tom X-array)
- [ ] `forbehandla_bild()` anv√§nds p√• identiskt s√§tt i ladda_bilder() och klassificera_callback()
- [ ] Kameran startar och procentsatser uppdateras i realtid
- [ ] PNG med alfa-kanal hanteras (convert('RGB') i ladda_bilder)
