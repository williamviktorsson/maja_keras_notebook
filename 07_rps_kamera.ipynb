{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Bygg din egen Sten-Sax-P√•se AI ü§ñ‚úä‚úã‚úåÔ∏è\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DITT-REPO/07_rps_kamera.ipynb)\n",
    "\n",
    "Du har l√§rt dig hur CNN:er fungerar. Nu bygger du ett fr√•n grunden ‚Äî tr√§nat p√• **dina egna bilder**.\n",
    "\n",
    "## Vad vi g√∂r\n",
    "1. Kopplar Google Drive och h√§mtar tr√§ningsdata\n",
    "2. Tr√§nar ett CNN p√• bilder av sten, sax och p√•se\n",
    "3. Testar modellen live med din webcam\n",
    "\n",
    "## Vad du beh√∂ver\n",
    "- Ett Google-konto med Drive\n",
    "- En kamera (inbyggd eller extern)\n",
    "- K√∂r cellerna uppifr√•n och ned, en i taget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "from google.colab import output as colab_output\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"Keras: {keras.__version__}\")\n",
    "print(\"Allt importerat! ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 1: F√∂rbehandling\n",
    "\n",
    "Samma funktion anv√§nds f√∂r **tr√§ningsbilder** och **live-kamerabilder** ‚Äî annars tr√§nar vi p√• en typ av data men testar p√• en annan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 150  # Alla bilder skalas till 150√ó150 pixlar\n",
    "KLASSER  = ['rock', 'paper', 'scissors']\n",
    "\n",
    "def forbehandla_bild(img):\n",
    "    \"\"\"\n",
    "    Tar en numpy RGB-array (valfri storlek) och returnerar\n",
    "    en normaliserad float32-array med formen (150, 150, 3).\n",
    "    Anv√§nds vid b√•de tr√§ning och live-inferens.\n",
    "    \"\"\"\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    return img.astype('float32') / 255.0\n",
    "\n",
    "# Snabbtest\n",
    "_dummy = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)\n",
    "assert forbehandla_bild(_dummy).shape == (IMG_SIZE, IMG_SIZE, 3)\n",
    "assert forbehandla_bild(_dummy).max() <= 1.0\n",
    "print(f\"forbehandla_bild(): {IMG_SIZE}√ó{IMG_SIZE} px, normaliserad till 0‚Äì1 ‚úì\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 2: Google Drive\n",
    "\n",
    "K√∂r cellen nedan. En popup √∂ppnas ‚Äî logga in med ditt Google-konto och ge tillst√•nd.\n",
    "\n",
    "Dina bilder sparas i Drive s√• att de finns kvar n√§sta g√•ng du √∂ppnar Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_ROOT   = '/content/drive/My Drive'\n",
    "EXEMPEL_DIR  = f'{DRIVE_ROOT}/rps_exempel'\n",
    "EGET_DIR     = f'{DRIVE_ROOT}/rps_eget'\n",
    "\n",
    "print(f\"Drive kopplat! ‚úì\")\n",
    "print(f\"Exempeldata: {EXEMPEL_DIR}\")\n",
    "print(f\"Egna bilder: {EGET_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 3: Exempeldata\n",
    "\n",
    "K√∂r den h√§r cellen **en g√•ng** f√∂r att fylla dina Drive-mappar med exempelbilder fr√•n ett f√§rdigt dataset.\n",
    "\n",
    "Mappstrukturen som skapas:\n",
    "```\n",
    "My Drive/\n",
    "  rps_exempel/\n",
    "    rock/        ‚Üê ~150 bilder\n",
    "    paper/       ‚Üê ~150 bilder\n",
    "    scissors/    ‚Üê ~150 bilder\n",
    "  rps_eget/\n",
    "    rock/        ‚Üê tom (fyll p√• med dina egna bilder!)\n",
    "    paper/       ‚Üê tom\n",
    "    scissors/    ‚Üê tom\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skapa_mappar(base_dir):\n",
    "    for klass in KLASSER:\n",
    "        os.makedirs(f'{base_dir}/{klass}', exist_ok=True)\n",
    "\n",
    "skapa_mappar(EXEMPEL_DIR)\n",
    "skapa_mappar(EGET_DIR)\n",
    "\n",
    "def spara_exempelbilder(data_dir, bilder_per_klass=150):\n",
    "    \"\"\"H√§mtar rock_paper_scissors fr√•n TF Datasets och sparar som JPG till Drive.\"\"\"\n",
    "    ds = tfds.load('rock_paper_scissors', split='train', as_supervised=True)\n",
    "\n",
    "    r√§knare = [0, 0, 0]\n",
    "    m√•l     = bilder_per_klass\n",
    "\n",
    "    for img_tensor, label_tensor in ds:\n",
    "        i = int(label_tensor.numpy())\n",
    "        if r√§knare[i] >= m√•l:\n",
    "            continue\n",
    "\n",
    "        img_pil = Image.fromarray(img_tensor.numpy().astype(np.uint8))\n",
    "        s√∂kv√§g  = f'{data_dir}/{KLASSER[i]}/{r√§knare[i]:04d}.jpg'\n",
    "        img_pil.save(s√∂kv√§g, quality=90)\n",
    "        r√§knare[i] += 1\n",
    "\n",
    "        if all(r >= m√•l for r in r√§knare):\n",
    "            break\n",
    "\n",
    "    for i, klass in enumerate(KLASSER):\n",
    "        print(f\"  {klass}: {r√§knare[i]} bilder sparade\")\n",
    "\n",
    "# Guard: hoppa √∂ver om mappen redan √§r ifylld\n",
    "rock_dir    = Path(f'{EXEMPEL_DIR}/rock')\n",
    "befintliga  = len(list(rock_dir.glob('*.jpg')))\n",
    "\n",
    "if befintliga >= 50:\n",
    "    print(f\"Exempelmappar redan ifyllda ({befintliga} bilder i rock/). Hoppar √∂ver. ‚úì\")\n",
    "else:\n",
    "    print(\"Laddar ner exempelbilder fr√•n TF Datasets...\")\n",
    "    print(\"(Tar ~1‚Äì2 minuter ‚Äî k√∂rs bara en g√•ng.)\\n\")\n",
    "    spara_exempelbilder(EXEMPEL_DIR)\n",
    "    print(f\"\\nKlart! Bilderna ligger nu i Drive under rps_exempel/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 4: V√§lj dataset\n",
    "\n",
    "√Ñndra `DATASET` nedan f√∂r att v√§lja vilka bilder modellen ska tr√§nas p√•.\n",
    "\n",
    "| V√§rde | Bilder |\n",
    "|-------|--------|\n",
    "| `'exempel'` | De 150 exempelbilder vi just laddade ner |\n",
    "| `'eget'` | Dina egna bilder i `rps_eget/` |\n",
    "\n",
    "**Hur l√§gger man till egna bilder?**\n",
    "1. √ñppna [drive.google.com](https://drive.google.com)\n",
    "2. Navigera till `rps_eget/rock/` och ladda upp foton av en knytn√§ve\n",
    "3. G√∂r samma f√∂r `paper/` och `scissors/`\n",
    "4. Minst 30 bilder per klass rekommenderas ‚Äî ju fler desto b√§ttre\n",
    "5. JPG, PNG, WebP ‚Äî alla format fungerar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'exempel'  # ‚Üê √Ñndra till 'eget' n√§r du har egna bilder\n",
    "\n",
    "if DATASET == 'exempel':\n",
    "    DATA_DIR = EXEMPEL_DIR\n",
    "elif DATASET == 'eget':\n",
    "    DATA_DIR = EGET_DIR\n",
    "else:\n",
    "    raise ValueError(f\"DATASET m√•ste vara 'exempel' eller 'eget', fick: '{DATASET}'\")\n",
    "\n",
    "print(f\"Anv√§nder dataset: '{DATASET}'\")\n",
    "print(f\"S√∂kv√§g: {DATA_DIR}\\n\")\n",
    "\n",
    "for klass in KLASSER:\n",
    "    klass_path = Path(f'{DATA_DIR}/{klass}')\n",
    "    filer = (list(klass_path.glob('*.jpg'))  +\n",
    "             list(klass_path.glob('*.jpeg')) +\n",
    "             list(klass_path.glob('*.png'))  +\n",
    "             list(klass_path.glob('*.webp')))\n",
    "    print(f\"  {klass}: {len(filer)} bilder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 5: Ladda och tr√§na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ladda_bilder(data_dir):\n",
    "    \"\"\"\n",
    "    Laddar alla bilder fr√•n data_dir/{rock,paper,scissors}/.\n",
    "    Returnerar X (numpy-array) och y (klassetiketter).\n",
    "    St√∂djer JPG, JPEG, PNG, WebP.\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    fel  = 0\n",
    "\n",
    "    for i, klass in enumerate(KLASSER):\n",
    "        klass_dir = Path(f'{data_dir}/{klass}')\n",
    "        filer = (list(klass_dir.glob('*.jpg'))  +\n",
    "                 list(klass_dir.glob('*.jpeg')) +\n",
    "                 list(klass_dir.glob('*.png'))  +\n",
    "                 list(klass_dir.glob('*.webp')))\n",
    "\n",
    "        laddade = 0\n",
    "        for fil in filer:\n",
    "            try:\n",
    "                img = Image.open(fil).convert('RGB')  # hanterar RGBA, gr√•skala etc.\n",
    "                img = forbehandla_bild(np.array(img))\n",
    "                X.append(img)\n",
    "                y.append(i)\n",
    "                laddade += 1\n",
    "            except Exception as e:\n",
    "                print(f\"  Varning: kunde inte ladda {fil.name}: {e}\")\n",
    "                fel += 1\n",
    "\n",
    "        print(f\"  {klass}: {laddade} bilder laddade\")\n",
    "\n",
    "    if fel:\n",
    "        print(f\"  ({fel} filer hoppades √∂ver)\")\n",
    "\n",
    "    return np.array(X, dtype='float32'), np.array(y, dtype='int32')\n",
    "\n",
    "print(\"Laddar bilder fr√•n Drive...\")\n",
    "X, y = ladda_bilder(DATA_DIR)\n",
    "print(f\"\\nX.shape: {X.shape}   y.shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visa 12 slumpm√§ssiga bilder\n",
    "fig, axes = plt.subplots(2, 6, figsize=(15, 5))\n",
    "idx = np.random.choice(len(X), 12, replace=False)\n",
    "\n",
    "for ax, i in zip(axes.flatten(), idx):\n",
    "    ax.imshow(X[i])\n",
    "    ax.set_title(KLASSER[y[i]])\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Exempelbilder fr√•n dataset', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Tr√§ning:    {len(X_train)} bilder\")\n",
    "print(f\"Validering: {len(X_val)} bilder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(3, activation='softmax')  # rock, paper, scissors\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tr√§nar modellen...\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "_, val_acc = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(f\"\\nValiderings-accuracy: {val_acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 6: Utv√§rdera modellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history.history['loss'],     label='Tr√§ning')\n",
    "axes[0].plot(history.history['val_loss'], label='Validering')\n",
    "axes[0].set_title('F√∂rlust (Loss)')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(history.history['accuracy'],     label='Tr√§ning')\n",
    "axes[1].plot(history.history['val_accuracy'], label='Validering')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix\n",
    "y_pred = np.argmax(model.predict(X_val, verbose=0), axis=1)\n",
    "cm     = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=KLASSER, yticklabels=KLASSER)\n",
    "plt.title('Confusion Matrix (validering)')\n",
    "plt.ylabel('Sant')\n",
    "plt.xlabel('F√∂rutsagt')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "## Del 7: Testa med webcam i realtid! üì∑\n",
    "\n",
    "K√∂r cellen nedan f√∂r att definiera kamera-funktionen, och sedan den sista cellen f√∂r att starta den.\n",
    "\n",
    "H√•ll upp handen med sten ‚úä, p√•se ‚úã eller sax ‚úåÔ∏è framf√∂r kameran!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def starta_kamera(model, klassnamn=None):\n",
    "    \"\"\"\n",
    "    Startar en live-kamerafeed i Colab och klassificerar varje frame.\n",
    "    Visar procentuella sannolikheter uppdaterade var 500ms.\n",
    "\n",
    "    Args:\n",
    "        model:     tr√§nad Keras-modell med softmax-output\n",
    "        klassnamn: lista med klassnamn, t.ex. ['rock', 'paper', 'scissors']\n",
    "    \"\"\"\n",
    "    if klassnamn is None:\n",
    "        klassnamn = KLASSER\n",
    "\n",
    "    # --- Python-callback som JS anropar ---\n",
    "    def klassificera_callback(img_b64):\n",
    "        binary    = base64.b64decode(img_b64.split(',')[1])\n",
    "        img_array = np.frombuffer(binary, dtype=np.uint8)\n",
    "        img_bgr   = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        img_rgb   = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        img_proc  = forbehandla_bild(img_rgb)\n",
    "        img_input = np.expand_dims(img_proc, axis=0)\n",
    "        pred      = model.predict(img_input, verbose=0)[0]\n",
    "        return {k: float(v) for k, v in zip(klassnamn, pred)}\n",
    "\n",
    "    colab_output.register_callback('klassificera_bild', klassificera_callback)\n",
    "\n",
    "    klass_json = json.dumps(klassnamn)\n",
    "    emoji_map  = json.dumps({'rock': '‚úä', 'paper': '‚úã', 'scissors': '‚úåÔ∏è'})\n",
    "\n",
    "    html = f\"\"\"\n",
    "<div id=\"rps-wrap\" style=\"font-family: 'Courier New', monospace; max-width: 400px;\">\n",
    "  <video id=\"rps-video\" width=\"320\" height=\"240\" autoplay playsinline\n",
    "         style=\"border: 2px solid #555; border-radius: 6px; display:block;\"></video>\n",
    "  <div id=\"rps-pred\" style=\"margin-top:10px; font-size:15px; line-height:2.2;\">\n",
    "    Startar kamera...\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "<script>\n",
    "(async () => {{\n",
    "  const video   = document.getElementById('rps-video');\n",
    "  const predDiv = document.getElementById('rps-pred');\n",
    "  const klasser = {klass_json};\n",
    "  const emojis  = {emoji_map};\n",
    "\n",
    "  const stream  = await navigator.mediaDevices.getUserMedia({{video: true}});\n",
    "  video.srcObject = stream;\n",
    "  await video.play();\n",
    "\n",
    "  const canvas  = document.createElement('canvas');\n",
    "  canvas.width  = video.videoWidth  || 320;\n",
    "  canvas.height = video.videoHeight || 240;\n",
    "\n",
    "  async function uppdatera() {{\n",
    "    canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);\n",
    "    const imgData = canvas.toDataURL('image/jpeg', 0.7);\n",
    "\n",
    "    let result;\n",
    "    try {{\n",
    "      result = await google.colab.kernel.invokeFunction(\n",
    "        'klassificera_bild', [imgData], {{}}\n",
    "      );\n",
    "    }} catch (e) {{\n",
    "      predDiv.innerHTML = '<span style=\"color:red;\">Fel: ' + e.message + '</span>';\n",
    "      return;\n",
    "    }}\n",
    "\n",
    "    const preds = result.data['application/json'];\n",
    "\n",
    "    let b√§staKlass = klasser[0];\n",
    "    let b√§staV√§rde = 0;\n",
    "    for (const k of klasser) {{\n",
    "      if (preds[k] > b√§staV√§rde) {{ b√§staV√§rde = preds[k]; b√§staKlass = k; }}\n",
    "    }}\n",
    "\n",
    "    let html = '';\n",
    "    for (const k of klasser) {{\n",
    "      const pct    = Math.round(preds[k] * 100);\n",
    "      const filled = Math.round(preds[k] * 20);\n",
    "      const bar    = '‚ñà'.repeat(Math.max(0, filled)) +\n",
    "                     '‚ñë'.repeat(Math.max(0, 20 - filled));\n",
    "      const isTop  = (k === b√§staKlass);\n",
    "      const color  = isTop\n",
    "        ? (pct >= 60 ? '#22c55e' : '#f59e0b')\n",
    "        : '#9ca3af';\n",
    "      const weight = isTop ? 'bold' : 'normal';\n",
    "      const emoji  = emojis[k] || '?';\n",
    "      html += `<div style=\"color:${{color}};font-weight:${{weight}};\">`\n",
    "            + `${{emoji}} ${{k.padEnd(9)}} ${{bar}} ${{String(pct).padStart(3)}}%</div>`;\n",
    "    }}\n",
    "    predDiv.innerHTML = html;\n",
    "  }}\n",
    "\n",
    "  setInterval(uppdatera, 500);\n",
    "}})();\n",
    "</script>\n",
    "\"\"\"\n",
    "    display(HTML(html))\n",
    "    print(\"Kameran √§r ig√•ng! H√•ll upp handen framf√∂r kameran. ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "starta_kamera(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
